{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome to Trio de Inform√°tica's Second IART Project about Topic Modelling using NLP\n",
    "\n",
    "Throughout this notebook you will see the step by step data analysis of the training datasets as well as different approaches to this challenge. Several algorithms will also be implemented such as Naive Bayes, decision trees, SVM, etc. Be aware that different data processing techniques can match different algorithms, so in order to test all the combinations we will provide several cells to present all the results. \n",
    "\n",
    "As to provide better insight on the training dataset, we will start by presenting a statistic overview of the provided data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "          ID                                              TITLE  \\\n0          1        Reconstructing Subject-Specific Effect Maps   \n1          2                 Rotation Invariance Neural Network   \n2          3  Spherical polyharmonics and Poisson kernels fo...   \n3          4  A finite element approximation for the stochas...   \n4          5  Comparative study of Discrete Wavelet Transfor...   \n...      ...                                                ...   \n20967  20968  Contemporary machine learning: a guide for pra...   \n20968  20969  Uniform diamond coatings on WC-Co hard alloy c...   \n20969  20970  Analysing Soccer Games with Clustering and Con...   \n20970  20971  On the Efficient Simulation of the Left-Tail o...   \n20971  20972   Why optional stopping is a problem for Bayesians   \n\n                                                ABSTRACT  Computer Science  \\\n0        Predictive models allow subject-specific inf...                 1   \n1        Rotation invariance and translation invarian...                 1   \n2        We introduce and develop the notion of spher...                 0   \n3        The stochastic Landau--Lifshitz--Gilbert (LL...                 0   \n4        Fourier-transform infra-red (FTIR) spectra o...                 1   \n...                                                  ...               ...   \n20967    Machine learning is finding increasingly bro...                 1   \n20968    Polycrystalline diamond coatings have been g...                 0   \n20969    We present a new approach for identifying si...                 1   \n20970    The sum of Log-normal variates is encountere...                 0   \n20971    Recently, optional stopping has been a subje...                 0   \n\n       Physics  Mathematics  Statistics  Quantitative Biology  \\\n0            0            0           0                     0   \n1            0            0           0                     0   \n2            0            1           0                     0   \n3            0            1           0                     0   \n4            0            0           1                     0   \n...        ...          ...         ...                   ...   \n20967        1            0           0                     0   \n20968        1            0           0                     0   \n20969        0            0           0                     0   \n20970        0            1           1                     0   \n20971        0            1           1                     0   \n\n       Quantitative Finance  \n0                         0  \n1                         0  \n2                         0  \n3                         0  \n4                         0  \n...                     ...  \n20967                     0  \n20968                     0  \n20969                     0  \n20970                     0  \n20971                     0  \n\n[20972 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Importing the dataset\n",
    "dataset = pd.read_csv('archive/train.csv')\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Info:<bound method DataFrame.info of           ID                                              TITLE  \\\n0          1        Reconstructing Subject-Specific Effect Maps   \n1          2                 Rotation Invariance Neural Network   \n2          3  Spherical polyharmonics and Poisson kernels fo...   \n3          4  A finite element approximation for the stochas...   \n4          5  Comparative study of Discrete Wavelet Transfor...   \n...      ...                                                ...   \n20967  20968  Contemporary machine learning: a guide for pra...   \n20968  20969  Uniform diamond coatings on WC-Co hard alloy c...   \n20969  20970  Analysing Soccer Games with Clustering and Con...   \n20970  20971  On the Efficient Simulation of the Left-Tail o...   \n20971  20972   Why optional stopping is a problem for Bayesians   \n\n                                                ABSTRACT  Computer Science  \\\n0        Predictive models allow subject-specific inf...                 1   \n1        Rotation invariance and translation invarian...                 1   \n2        We introduce and develop the notion of spher...                 0   \n3        The stochastic Landau--Lifshitz--Gilbert (LL...                 0   \n4        Fourier-transform infra-red (FTIR) spectra o...                 1   \n...                                                  ...               ...   \n20967    Machine learning is finding increasingly bro...                 1   \n20968    Polycrystalline diamond coatings have been g...                 0   \n20969    We present a new approach for identifying si...                 1   \n20970    The sum of Log-normal variates is encountere...                 0   \n20971    Recently, optional stopping has been a subje...                 0   \n\n       Physics  Mathematics  Statistics  Quantitative Biology  \\\n0            0            0           0                     0   \n1            0            0           0                     0   \n2            0            1           0                     0   \n3            0            1           0                     0   \n4            0            0           1                     0   \n...        ...          ...         ...                   ...   \n20967        1            0           0                     0   \n20968        1            0           0                     0   \n20969        0            0           0                     0   \n20970        0            1           1                     0   \n20971        0            1           1                     0   \n\n       Quantitative Finance  \n0                         0  \n1                         0  \n2                         0  \n3                         0  \n4                         0  \n...                     ...  \n20967                     0  \n20968                     0  \n20969                     0  \n20970                     0  \n20971                     0  \n\n[20972 rows x 9 columns]>\nShape: (20972, 9)\n"
     ]
    }
   ],
   "source": [
    "print(\"Info:\" + str(dataset.info))\n",
    "print(\"Shape: \"+ str(dataset.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "As count:\n\nComputer Science:  8594\nPhysics:  6013\nMathematics:  5618\nStatistics:  5206\nQuantitative Biology:  587\nQuantitative Finance:  249\n\nAs a percentage:\n\nComputer Science:  41 %\nPhysics:  29 %\nMathematics:  27 %\nStatistics:  25 %\nQuantitative Biology:  3 %\nQuantitative Finance:  1 %\n"
     ]
    }
   ],
   "source": [
    "print('As count:\\n')\n",
    "print('Computer Science: ',dataset['Computer Science'].sum())\n",
    "print('Physics: ',dataset['Physics'].sum())\n",
    "print('Mathematics: ',dataset['Mathematics'].sum())\n",
    "print('Statistics: ',dataset['Statistics'].sum())\n",
    "print('Quantitative Biology: ',dataset['Quantitative Biology'].sum())\n",
    "print('Quantitative Finance: ',dataset['Quantitative Finance'].sum())\n",
    "\n",
    "print('\\nAs a percentage:\\n')\n",
    "print('Computer Science: ',round(dataset['Computer Science'].sum()/dataset.shape[0]*100), '%')\n",
    "print('Physics: ',round(dataset['Physics'].sum()/dataset.shape[0]*100),'%')\n",
    "print('Mathematics: ',round(dataset['Mathematics'].sum()/dataset.shape[0]*100),'%')\n",
    "print('Statistics: ',round(dataset['Statistics'].sum()/dataset.shape[0]*100),'%')\n",
    "print('Quantitative Biology: ',round(dataset['Quantitative Biology'].sum()/dataset.shape[0]*100),'%')\n",
    "print('Quantitative Finance: ',round(dataset['Quantitative Finance'].sum()/dataset.shape[0]*100),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preProcessStem():\n",
    "\n",
    "    corpus=[]\n",
    "    # Initialize PorterStemmer\n",
    "    ps = PorterStemmer()\n",
    "\n",
    "    for i in range(0,dataset.shape[0]):\n",
    "        # get review and remove non alpha chars\n",
    "        title = re.sub('[^a-zA-Z]', ' ', dataset['TITLE'][i])\n",
    "        abstract = re.sub('[^a-zA-Z]', ' ', dataset['ABSTRACT'][i])\n",
    "        # to lower-case and tokenize\n",
    "        title = title.lower().split()\n",
    "        abstract = abstract.lower().split()\n",
    "        # stemming and stop word removal\n",
    "        title = ' '.join([ps.stem(w) for w in title if not w in set(stopwords.words('english'))])\n",
    "        abstract = ' '.join([ps.stem(w) for w in abstract if not w in set(stopwords.words('english'))])\n",
    "        corpus.append((title, abstract))\n",
    "        print((title, abstract))\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " 'overset method commonly employed enable effective simulation problem involving complex geometry moving object rotorcraft paper present novel overset domain connectivity algorithm based upon direct cut approach suitable use gpu accelerated solver high order curved grid contrast previous method capable exploiting highly data parallel nature modern accelerator approach also substantially efficient handling curved grid arise within context high order method implementation new algorithm presented combined high order fluid dynamic code algorithm validated several benchmark problem including flow spinning golf ball reynolds number')\n",
      "('data assimilation algorithm paradigm leray alpha model turbulence', 'paper survey various implementation new data assimilation downscaling algorithm based spatial coarse mesh measurement paradigm demonstrate application algorithm leray alpha subgrid scale turbulence model importantly use paradigm show always necessary one collect coarse mesh measurement state variable involved underlying evolutionary system order recover corresponding exact reference solution specifically show case leray alpha model turbulence solution algorithm constructed using coarse mesh observation two component three dimensional velocity field without information third component converge exponential rate time corresponding exact reference solution leray alpha model study serf addendum recent work abridged continuous data assimilation navier stokes equation notably similar result also recently established viscous planetary geostrophic circulation model show coarse mesh measurement temperature alone sufficient recovering data assimilation algorithm full solution viz three component velocity vector field temperature consequently prof charney conjecture planetary geostrophic model namely history large spatial scale temperature sufficient determining quantity state variable model')\n",
      "('playing true parrondo game three state coin quantum walk', 'playing parrondo game qutrit subject paper show true quantum parrondo game played state coin qutrit quantum walk contrast fact playing true parrondo game state coin qubit quantum walk fails asymptotic limit')\n",
      "('cross modal recurrent model weight objective prediction multimodal time series data', 'analyse multimodal time series data corresponding weight sleep step measurement focus predicting whether user successfully achieve weight objective design several deep long short term memory lstm architecture including novel cross modal lstm x lstm demonstrate superiority baseline approach x lstm improves parameter efficiency processing modality separately allowing information flow way recurrent cross connection present general hyperparameter optimisation technique x lstms allows u significantly improve lstm prior state art cross modal approach using comparable number parameter finally visualise model prediction revealing implication latent variable task')\n",
      "('spatial variational auto encoding via matrix variate normal distribution', 'key idea variational auto encoders vaes resembles traditional auto encoder model spatial information supposed explicitly encoded latent space however latent variable vaes vector interpreted multiple feature map size x representation convey spatial information implicitly coupled powerful decoder work propose spatial vaes use feature map larger size latent variable explicitly capture spatial information achieved allowing latent variable sampled matrix variate normal mvn distribution whose parameter computed encoder network increase dependency among location latent feature map reduce number parameter propose spatial vaes via low rank mvn distribution experimental result show proposed spatial vaes outperform original vaes capturing rich structural spatial information')\n",
      "('optimal ramp scheme related combinatorial object', 'jackson martin proved strong ideal ramp scheme equivalent orthogonal array however good characterization ideal ramp scheme strong show equivalence ideal ramp scheme new variant orthogonal array term augmented orthogonal array give construction new kind array consequence also provide parameter situation ideal ramp scheme exist strong ideal ramp scheme exist')\n",
      "('neural net learn statistical law behind natural language', 'performance deep learning natural language processing spectacular reason success remain unclear inherent complexity deep learning paper provides empirical evidence effectiveness limitation neural network language engineering precisely demonstrate neural language model based long short term memory lstm effectively reproduces zipf law heap law two representative statistical property underlying natural language discus quality reproducibility emergence zipf law heap law training progress also point neural language model limitation reproducing long range correlation another statistical property natural language understanding could provide direction improving architecture neural network')\n",
      "('super speed zero ram next generation large scale optimization laptop', 'article present novel breakthrough general purpose algorithm large scale optimization problem novel algorithm capable achieving breakthrough speed large scale optimization general purpose laptop embedded system application algorithm griewank function possible billion decision variable double precision took second hour solve consuming mb gb ram single threaded laptop cpu show algorithm computationally memory space linearly efficient find optimal near optimal solution fraction time memory many conventional algorithm require envisaged open new possibility real time large scale problem personal laptop embedded system')\n",
      "('recoverable energy dissipative electromagnetic system', 'ambiguity definition stored energy within distributed radiating electromagnetic system motivate discussion well defined concept recoverable energy concept commonly overlooked community purpose communication recall existence discus relationship fractional bandwidth using rational function approximation system input impedance recoverable energy lumped radiating system calculated closed form related stored energy fractional bandwidth lumped circuit also used demonstrate relationship recoverable energy energy stored within equivalent circuit produced minimum phase shift darlington synthesis procedure')\n",
      "('elliptic hall algebra mathbb f', 'construct hall algebra elliptic curve mathbb f using theory monoidal scheme due deitmar theory hall algebra monoidal representation due szczesny resulting algebra shown specialization elliptic hall algebra studied burban schiffmann thus algebra isomorphic skein algebra torus recent work morton samuelson')\n",
      "('approximate bayesian inference queueing network coupled jump process', 'queueing network system theoretical interest give rise complex family stochastic process find widespread use performance evaluation interconnected resource yet despite importance within application comparison counterpart stochastic model genetics mathematical biology exist relevant approach transient inference uncertainty quantification task system consequence strong computational impediment distinctive property markov jump process induced queueing network paper offer comprehensive overview inferential challenge comparison analogue task within related mathematical domain discus model augmentation approximating network system present flexible scalable variational bayesian framework targeted general form open closed queueing system varied service discipline priority inferential procedure finally validated couple uncertainty quantification task network service rate')\n",
      "('universal feature price formation financial market perspective deep learning', 'using large scale deep learning approach applied high frequency database containing billion electronic market quote transaction u equity uncover nonparametric evidence existence universal stationary price formation mechanism relating dynamic supply demand stock revealed order book subsequent variation market price ass model testing sample prediction direction price move given history price order flow across wide range stock time period universal price formation model shown exhibit remarkably stable sample prediction accuracy across time wide range stock different sector interestingly result also hold stock part training sample showing relation captured model universal asset specific universal model trained data stock outperforms term sample prediction accuracy asset specific linear nonlinear model trained time series given stock showing universal nature price formation weighs favour pooling together financial data various stock rather designing asset sector specific model commonly done standard data normalization based volatility price level average spread partitioning training data sector category large small tick stock improve training result hand inclusion price order flow history many past observation shown improve forecasting performance showing evidence path dependence price dynamic')\n",
      "('new tracking algorithm multiple colloidal particle close contact', 'paper propose new algorithm based radial symmetry center method track colloidal particle close contact optical image particle start overlap digital video microscopy overlapping effect important observe pair interaction potential colloidal study appears additional interaction measurement interaction conventional tracking analysis proposed algorithm work simple fast applicable two particle also three particle without modification algorithm us gradient vector particle intensity distribution allows u use part symmetric intensity distribution calculation actual particle position study simulation performed see performance proposed algorithm two three particle simulation image generated using fitted curve experimental particle image different sized particle result algorithm yield maximum error smaller nm mu silica particle contact condition')\n",
      "('critical percolation without fine tuning surface topological superconductor', 'present numerical evidence two dimensional surface state bulk topological superconductor tsc sit integer quantum hall plateau transition study tsc surface state class ci quenched disorder low energy finite energy surface state expected critically delocalized anderson localized confirm low energy picture find instead finite energy state also delocalized universal statistic independent tsc winding number consistent spin quantum hall plateau transition percolation')\n",
      "('low luminosity stellar wind accretion onto neutron star hmxbs', 'feature application quasi spherical settling accretion onto rotating magnetized neutron star high mass x ray binary discussed settling accretion occurs wind fed hmxbs plasma cooling time longer free fall time gravitational capture radius take place low luminosity hmxbs l x lesssim time erg briefly review implication settling accretion focusing sfxt phenomenon related instability quasi spherical convective shell neutron star magnetosphere due magnetic reconnection fast temporarily magnetized wind ob supergiant young neutron star wind fed hmxb rapidly rotating propeller regime quasi spherical hot shell occurs show x ray spectral temporal property enigmatic gamma ca star consistent failed settling accretion regime onto propelling neutron star subsequent evolutionary stage gamma ca analog x per type binary comprising low luminosity slowly rotating x ray pulsar')\n",
      "('faithful inversion generative model effective amortized inference', 'inference amortization method share information across multiple posterior inference problem allowing carried efficiently generally require inversion dependency structure generative model modeller must learn mapping observation distribution approximating posterior previous approach involved inverting dependency structure heuristic way fails capture dependency correctly thereby limiting achievable accuracy resulting approximation introduce algorithm faithfully minimally inverting graphical model structure generative model inverse two crucial property encode independence assertion absent model b local maximum number true independency encoded prove correctness approach empirically show resulting minimally faithful inverse lead better inference amortization existing heuristic approach')\n",
      "('social network analysis operation research industrial engineering faculty hiring network', 'study u operation research industrial system engineering orie faculty hiring network consisting faculty origin destination data together attribute data orie department social network analysis faculty hire reveal important pattern academic field existence hierarchy sociological aspect presence community department first statistically test existence linear hierarchy network steepness find near linear hierarchical order department proposing new index hiring network contrast indicator hierarchy including published ranking single index capable capture full structure complex network however next fit latent exponential random graph model ergm network able reproduce main observed characteristic high incidence self hiring skewed degree distribution low density clustering finally use latent variable ergm simplify network one faculty hire take place among three group department contrast finding reported related discipline computer science business')\n",
      "('one sample aggregate data meta analysis median', 'aggregate data meta analysis statistical method pool summary statistic several selected study estimate outcome interest considering continuous outcome typically study must report measure outcome variable spread e g sample mean standard error however study may instead report median along various measure spread recently task incorporating median meta analysis achieved estimating sample mean standard error study report median order meta analyze mean paper propose two alternative approach meta analyze data instead rely median systematically compare approach via simulation study method transform study specific median spread sample mean standard error demonstrate proposed median based approach perform better transformation based approach especially applied skewed data data high inter study variance addition meta analyzing data consists median show median based approach perform considerably better comparably best case scenario transformation approach conducting meta analysis using actual sample mean standard error mean study finally illustrate approach meta analysis patient delay tuberculosis diagnosis')\n",
      "('quickcast fast efficient inter datacenter transfer using forwarding tree cohort', 'large inter datacenter transfer crucial cloud service efficiency increasingly used organization dedicated wide area network datacenters recent work us multicast forwarding tree reduce bandwidth need improve completion time point multipoint transfer using single forwarding tree per transfer however lead poor performance slowest receiver dictate completion time receiver using multiple forwarding tree per transfer alleviates concern average receiver could finish early however done naively bandwidth usage would also increase apriori unclear best partition receiver construct multiple tree determine rate schedule flow tree paper present quickcast first solution problem using simulation real world network topology see quickcast speed average receiver completion time much time using time bandwidth completion time receiver also improves much time faster high load')\n",
      "('contemporary machine learning guide practitioner physical science', 'machine learning finding increasingly broad application physical science often involves building model relationship dependent measurable output associated set controllable complicated independent input present tutorial current technique machine learning jumping point interested researcher advance work focus deep neural network emphasis demystifying deep learning begin background idea machine learning example application current research plasma physic discus supervised learning technique modeling complicated function beginning familiar regression scheme advancing sophisticated deep learning method also address unsupervised learning technique reducing dimensionality input space along way describe method practitioner help ensure model generalize training data yet unseen test data describe class task predicting scalar handling image fitting time series prepare reader choose appropriate technique finally point limitation modern machine learning speculate way practitioner physical science may particularly suited help')\n",
      "('uniform diamond coating wc co hard alloy cutting insert deposited microwave plasma cvd', 'polycrystalline diamond coating grown cemented carbide substrate different aspect ratio microwave plasma cvd methane hydrogen gas mixture protect edge substrate non uniform heating due plasma edge effect special plateholder pocket group growth used difference height substrate plateholder influence diamond film mean grain size growth rate phase composition stress investigated substrate temperature range within uniform diamond film produced good adhesion determined diamond coated cutting insert produced optimized process exhibited reduction cutting force wear resistance factor two cutting efficiency increase time upon turning al si alloy compared performance uncoated tool')\n",
      "('analysing soccer game clustering conceptors', 'present new approach identifying situation behaviour call move soccer game simulation league able identify key situation behaviour useful capability analysing soccer match anticipating opponent behaviour aid selection appropriate tactic also prerequisite automatic learning behaviour policy support wide set strategy goal identify situation data unsupervised way without making use pre defined soccer specific concept pas dribble recurrent neural network use approach act high dimensional projection recent history situation field similar situation e similar history found clustering network state network also used learn called conceptors lower dimensional manifold describe trajectory high dimensional state space enable situation specific prediction neural network proposed approach segment game sequence situation learnt unsupervised way learn conceptors useful prediction near future respective situation')\n",
      "('efficient simulation left tail sum correlated log normal variate', 'sum log normal variate encountered many challenging application performance analysis wireless communication system financial engineering several approximation method developed literature accuracy ensured tail region region primordial interest wherein small probability value evaluated high precision variance reduction technique known yield accurate yet efficient estimate small probability value existing approach however considered problem estimating right tail sum log normal random variable rv present work consider instead estimation left tail sum correlated log normal variate gaussian copula mild assumption covariance matrix propose estimator combining existing mean shifting importance sampling approach control variate technique main result proposed estimator asymptotically vanishing relative error represents major finding context left tail simulation sum log normal rv finally ass various simulation result performance proposed estimator compared existing estimator')\n",
      "('optional stopping problem bayesians', 'recently optional stopping subject debate bayesian psychology community rouder argues optional stopping problem bayesians even recommends use optional stopping practice wagenmakers et al article address question whether optional stopping problematic bayesian method specifies circumstance sense slightly varying extending rouder experiment illustrate soon parameter interest equipped default pragmatic prior mean practical application bayes factor hypothesis testing resilience optional stopping break distinguish four type default prior specific issue optional stopping ranging problem type prior quite severe type ii iii prior')\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def preProcessLem():\n",
    "    corpus=[]\n",
    "    # Initialize Word Net Lemmatizer\n",
    "    ps = WordNetLemmatizer()\n",
    "\n",
    "    for i in range(0,dataset.shape[0]):\n",
    "        # get review and remove non alpha chars\n",
    "        title = re.sub('[^a-zA-Z]', ' ', dataset['TITLE'][i])\n",
    "        abstract = re.sub('[^a-zA-Z]', ' ', dataset['ABSTRACT'][i])\n",
    "        # to lower-case and tokenize\n",
    "        title = title.lower().split()\n",
    "        abstract = abstract.lower().split()\n",
    "        # lemmatization and stop word removal\n",
    "        title = ' '.join([ps.lemmatize(w) for w in title if not w in set(stopwords.words('english'))])\n",
    "        abstract = ' '.join([ps.lemmatize(w) for w in abstract if not w in set(stopwords.words('english'))])\n",
    "        corpus.append((title, abstract))\n",
    "        print((title, abstract))\n",
    "    return corpus\n",
    "\n",
    "corpus = preProcessLem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for (title, abstract) in corpus:\n",
    "    data.append(title + abstract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['ability', 'able', 'absorption', 'abstract', 'abundance', 'access', 'according', 'account', 'accuracy', 'accurate', 'accurately', 'achieve', 'achieved', 'achieves', 'achieving', 'acoustic', 'across', 'action', 'activation', 'active', 'activity', 'ad', 'adaptation', 'adaptive', 'addition', 'additional', 'additionally', 'address', 'advance', 'advantage', 'adversarial', 'affect', 'affine', 'age', 'agent', 'agreement', 'aim', 'al', 'algebra', 'algebraic', 'algorithm', 'alignment', 'allocation', 'allow', 'allowing', 'allows', 'almost', 'along', 'alpha', 'already', 'also', 'alternative', 'although', 'always', 'among', 'amount', 'amplitude', 'analysis', 'analytic', 'analytical', 'analyze', 'analyzed', 'analyzing', 'angle', 'angular', 'anisotropic', 'anisotropy', 'anomaly', 'another', 'answer', 'appear', 'applicable', 'application', 'applied', 'apply', 'applying', 'approach', 'appropriate', 'approximate', 'approximately', 'approximation', 'arbitrary', 'architecture', 'area', 'argument', 'arise', 'arm', 'around', 'array', 'art', 'article', 'artificial', 'aspect', 'ass', 'assessment', 'associated', 'assume', 'assuming', 'assumption', 'asymptotic', 'asymptotically', 'atom', 'atomic', 'attack', 'attention', 'attribute', 'author', 'automated', 'automatic', 'automatically', 'autonomous', 'available', 'average', 'back', 'background', 'band', 'bandit', 'base', 'based', 'baseline', 'basic', 'basis', 'batch', 'bayesian', 'beam', 'become', 'becomes', 'behavior', 'behaviour', 'benchmark', 'benefit', 'best', 'beta', 'better', 'beyond', 'bi', 'bias', 'big', 'binary', 'biological', 'bit', 'black', 'block', 'body', 'bound', 'boundary', 'bounded', 'box', 'brain', 'broad', 'build', 'building', 'built', 'bulk', 'bundle', 'calculate', 'calculated', 'calculation', 'call', 'called', 'camera', 'candidate', 'cannot', 'canonical', 'capability', 'capable', 'capacity', 'capture', 'carlo', 'case', 'category', 'causal', 'cause', 'cavity', 'cdot', 'cell', 'center', 'central', 'certain', 'chain', 'challenge', 'challenging', 'change', 'channel', 'character', 'characteristic', 'characterization', 'characterize', 'characterized', 'charge', 'chemical', 'choice', 'chosen', 'circuit', 'class', 'classical', 'classification', 'classifier', 'close', 'closed', 'cloud', 'cluster', 'clustering', 'cm', 'cnn', 'co', 'code', 'coding', 'coefficient', 'coherent', 'collected', 'collection', 'collective', 'collision', 'color', 'combination', 'combinatorial', 'combine', 'combined', 'combining', 'come', 'common', 'commonly', 'communication', 'community', 'compact', 'comparable', 'compare', 'compared', 'comparing', 'comparison', 'competitive', 'complete', 'completely', 'complex', 'complexity', 'component', 'composition', 'compound', 'compression', 'computation', 'computational', 'computationally', 'compute', 'computed', 'computer', 'computing', 'concentration', 'concept', 'conclude', 'condition', 'conditional', 'conducted', 'confidence', 'configuration', 'confirm', 'conjecture', 'connected', 'connection', 'connectivity', 'consequence', 'consider', 'considered', 'considering', 'consistency', 'consistent', 'consisting', 'consists', 'constant', 'constrained', 'constraint', 'construct', 'constructed', 'construction', 'contact', 'containing', 'contains', 'content', 'context', 'continuous', 'continuum', 'contrast', 'contribution', 'control', 'controlled', 'controller', 'conventional', 'convergence', 'convex', 'convolution', 'convolutional', 'coordinate', 'core', 'correct', 'correction', 'correlated', 'correlation', 'correspondence', 'corresponding', 'cosmic', 'cosmological', 'cost', 'could', 'counterpart', 'coupled', 'coupling', 'covariance', 'cover', 'coverage', 'criterion', 'critical', 'cross', 'crucial', 'crystal', 'current', 'currently', 'curvature', 'curve', 'cycle', 'dark', 'data', 'database', 'dataset', 'datasets', 'day', 'de', 'deal', 'decade', 'decay', 'decision', 'decomposition', 'decrease', 'deep', 'defect', 'define', 'defined', 'definition', 'deformation', 'degree', 'delay', 'delta', 'demand', 'demonstrate', 'demonstrated', 'dense', 'density', 'depend', 'dependence', 'dependency', 'dependent', 'depending', 'depends', 'depth', 'derivative', 'derive', 'derived', 'descent', 'describe', 'described', 'describes', 'description', 'design', 'designed', 'desired', 'despite', 'detail', 'detailed', 'detect', 'detected', 'detecting', 'detection', 'detector', 'determine', 'determined', 'deterministic', 'develop', 'developed', 'developing', 'development', 'deviation', 'device', 'diagram', 'difference', 'different', 'differential', 'difficult', 'difficulty', 'diffusion', 'digital', 'dimension', 'dimensional', 'dimensionality', 'dirac', 'direct', 'directed', 'direction', 'directly', 'discovery', 'discrete', 'discus', 'discussed', 'disease', 'disk', 'disorder', 'dispersion', 'distance', 'distinct', 'distributed', 'distribution', 'divergence', 'diverse', 'domain', 'done', 'double', 'drift', 'driven', 'driving', 'dual', 'due', 'dust', 'dwarf', 'dynamic', 'dynamical', 'early', 'earth', 'easily', 'easy', 'edge', 'effect', 'effective', 'effectively', 'effectiveness', 'efficiency', 'efficient', 'efficiently', 'effort', 'eigenvalue', 'either', 'electric', 'electron', 'electronic', 'element', 'ell', 'elliptic', 'em', 'embedded', 'embedding', 'embeddings', 'emission', 'emph', 'empirical', 'empirically', 'employ', 'employed', 'enable', 'enables', 'encoding', 'end', 'energy', 'engineering', 'enhanced', 'enough', 'ensemble', 'entire', 'entity', 'entropy', 'environment', 'epsilon', 'equal', 'equation', 'equilibrium', 'equivalence', 'equivalent', 'error', 'especially', 'essential', 'establish', 'established', 'estimate', 'estimated', 'estimating', 'estimation', 'estimator', 'et', 'euclidean', 'evaluate', 'evaluated', 'evaluation', 'even', 'event', 'every', 'evidence', 'evolution', 'evolutionary', 'exact', 'exactly', 'examine', 'example', 'exchange', 'excitation', 'execution', 'exhibit', 'exist', 'existence', 'existing', 'exists', 'expansion', 'expected', 'experience', 'experiment', 'experimental', 'experimentally', 'expert', 'explain', 'explicit', 'explicitly', 'exploit', 'exploration', 'explore', 'exponent', 'exponential', 'expression', 'extend', 'extended', 'extension', 'extensive', 'external', 'extract', 'extraction', 'extreme', 'extremely', 'face', 'fact', 'factor', 'factorization', 'failure', 'family', 'far', 'fast', 'faster', 'fe', 'feature', 'feedback', 'fermi', 'fermion', 'field', 'film', 'filter', 'filtering', 'final', 'finally', 'find', 'finding', 'fine', 'finite', 'first', 'fit', 'fitting', 'five', 'fixed', 'flat', 'flexible', 'flow', 'fluctuation', 'fluid', 'flux', 'focus', 'follow', 'following', 'force', 'form', 'formal', 'formation', 'forming', 'formula', 'formulation', 'forward', 'found', 'four', 'fourier', 'frac', 'fraction', 'fractional', 'frame', 'framework', 'free', 'frequency', 'full', 'fully', 'function', 'functional', 'fundamental', 'furthermore', 'future', 'gain', 'galactic', 'galaxy', 'game', 'gamma', 'gan', 'gap', 'gas', 'gaussian', 'gene', 'general', 'generalization', 'generalize', 'generalized', 'generally', 'generate', 'generated', 'generating', 'generation', 'generative', 'generator', 'generic', 'geometric', 'geometry', 'geq', 'give', 'given', 'global', 'goal', 'good', 'gradient', 'graph', 'graphene', 'graphical', 'gravitational', 'gravity', 'great', 'grid', 'ground', 'group', 'growth', 'guarantee', 'half', 'halo', 'hamiltonian', 'hand', 'handle', 'hard', 'hardware', 'harmonic', 'health', 'heat', 'heavy', 'help', 'hence', 'heterogeneous', 'heuristic', 'hidden', 'hierarchical', 'high', 'higher', 'highlight', 'highly', 'history', 'hold', 'hole', 'homogeneous', 'host', 'hot', 'however', 'human', 'hybrid', 'hyperbolic', 'hypothesis', 'idea', 'ideal', 'identification', 'identified', 'identify', 'identifying', 'identity', 'ii', 'iii', 'illustrate', 'image', 'imaging', 'impact', 'implement', 'implementation', 'implemented', 'implication', 'implies', 'importance', 'important', 'improve', 'improved', 'improvement', 'improves', 'improving', 'include', 'includes', 'including', 'increase', 'increased', 'increasing', 'increasingly', 'independent', 'index', 'indicate', 'individual', 'induced', 'inequality', 'inference', 'infinite', 'influence', 'information', 'infrared', 'infty', 'initial', 'inner', 'input', 'inside', 'insight', 'inspired', 'instability', 'instance', 'instead', 'integer', 'integral', 'integrated', 'integration', 'intensity', 'inter', 'interacting', 'interaction', 'interest', 'interesting', 'interface', 'interference', 'intermediate', 'internal', 'interpretation', 'interval', 'intrinsic', 'introduce', 'introduced', 'introduces', 'introducing', 'invariant', 'inverse', 'investigate', 'investigated', 'investigation', 'involves', 'involving', 'ion', 'issue', 'item', 'iteration', 'iterative', 'joint', 'kernel', 'key', 'kind', 'kinetic', 'knowledge', 'known', 'label', 'labeled', 'lack', 'lagrangian', 'lambda', 'language', 'large', 'larger', 'laser', 'last', 'latent', 'latter', 'lattice', 'law', 'layer', 'le', 'lead', 'leading', 'learn', 'learned', 'learning', 'learns', 'least', 'left', 'length', 'leq', 'let', 'level', 'leverage', 'library', 'lie', 'life', 'light', 'like', 'likelihood', 'likely', 'limit', 'limitation', 'limited', 'line', 'linear', 'link', 'liquid', 'literature', 'little', 'load', 'local', 'localization', 'localized', 'locally', 'location', 'log', 'logic', 'long', 'loop', 'loss', 'low', 'lower', 'lstm', 'machine', 'made', 'magnetic', 'magnitude', 'main', 'major', 'make', 'making', 'management', 'manifold', 'manner', 'many', 'map', 'mapping', 'market', 'markov', 'mass', 'massive', 'match', 'matching', 'material', 'mathbb', 'mathbf', 'mathcal', 'mathematical', 'mathfrak', 'mathrm', 'matrix', 'matter', 'maximal', 'maximum', 'may', 'mean', 'measure', 'measured', 'measurement', 'mechanical', 'mechanism', 'medical', 'medium', 'memory', 'message', 'meta', 'metal', 'method', 'methodology', 'metric', 'might', 'minimal', 'minimization', 'minimum', 'mining', 'missing', 'mixed', 'mixing', 'mixture', 'mobile', 'mode', 'model', 'modeled', 'modeling', 'modelling', 'modern', 'modified', 'modular', 'module', 'molecular', 'molecule', 'moment', 'momentum', 'monte', 'moreover', 'motion', 'motivated', 'moving', 'mu', 'much', 'multi', 'multiple', 'multivariate', 'must', 'namely', 'natural', 'naturally', 'nature', 'near', 'nearly', 'necessary', 'need', 'needed', 'negative', 'neighbor', 'net', 'network', 'neural', 'neuron', 'new', 'next', 'nm', 'node', 'noise', 'noisy', 'non', 'nonlinear', 'nonparametric', 'norm', 'normal', 'note', 'notion', 'novel', 'number', 'numerical', 'numerically', 'object', 'objective', 'observation', 'observe', 'observed', 'obtain', 'obtained', 'offer', 'often', 'omega', 'one', 'online', 'open', 'operation', 'operator', 'optical', 'optimal', 'optimization', 'optimized', 'orbit', 'orbital', 'order', 'ordered', 'origin', 'original', 'orthogonal', 'oscillation', 'outcome', 'outlier', 'outperform', 'outperforms', 'output', 'overall', 'pair', 'paper', 'paradigm', 'parallel', 'parameter', 'parametric', 'part', 'partial', 'partially', 'particle', 'particular', 'particularly', 'partition', 'past', 'path', 'patient', 'pattern', 'peak', 'people', 'per', 'perform', 'performance', 'performed', 'performing', 'performs', 'period', 'periodic', 'perspective', 'perturbation', 'phase', 'phenomenon', 'phi', 'photon', 'physic', 'physical', 'pi', 'pixel', 'place', 'planar', 'plane', 'planet', 'planning', 'plasma', 'platform', 'play', 'player', 'pm', 'point', 'poisson', 'polarization', 'policy', 'polynomial', 'popular', 'population', 'pose', 'position', 'positive', 'possibility', 'possible', 'post', 'posterior', 'potential', 'potentially', 'power', 'powerful', 'practical', 'practice', 'pre', 'precision', 'predict', 'predicted', 'predicting', 'prediction', 'predictive', 'preference', 'presence', 'present', 'presented', 'preserving', 'pressure', 'previous', 'previously', 'price', 'primary', 'prime', 'principal', 'principle', 'prior', 'privacy', 'probabilistic', 'probability', 'probe', 'problem', 'procedure', 'process', 'processing', 'produce', 'produced', 'product', 'production', 'profile', 'program', 'programming', 'project', 'projection', 'promising', 'proof', 'propagation', 'proper', 'property', 'propose', 'proposed', 'proposes', 'protein', 'protocol', 'prove', 'proved', 'provide', 'provided', 'provides', 'providing', 'pseudo', 'public', 'pulse', 'purpose', 'quadratic', 'quality', 'quantitative', 'quantity', 'quantum', 'quasi', 'query', 'question', 'radial', 'radiation', 'radio', 'radius', 'random', 'range', 'rank', 'ranking', 'rate', 'rather', 'ratio', 'rational', 'ray', 'reach', 'reaction', 'real', 'realistic', 'reason', 'recent', 'recently', 'recognition', 'recommendation', 'reconstruction', 'recovery', 'recurrent', 'redshift', 'reduce', 'reduced', 'reduces', 'reducing', 'reduction', 'reference', 'regime', 'region', 'regression', 'regret', 'regular', 'regularity', 'regularization', 'reinforcement', 'related', 'relation', 'relationship', 'relative', 'relatively', 'relaxation', 'relevant', 'reliable', 'relies', 'rely', 'remains', 'report', 'reported', 'represent', 'representation', 'represented', 'require', 'required', 'requirement', 'requires', 'research', 'researcher', 'residual', 'resolution', 'resolved', 'resonance', 'resource', 'respect', 'respectively', 'response', 'restricted', 'result', 'resulting', 'retrieval', 'reveal', 'reveals', 'review', 'reward', 'rich', 'riemannian', 'right', 'ring', 'rise', 'risk', 'rm', 'robot', 'robust', 'robustness', 'role', 'root', 'rotation', 'rule', 'run', 'running', 'sample', 'sampling', 'satellite', 'scalable', 'scalar', 'scale', 'scaling', 'scattering', 'scenario', 'scene', 'scheme', 'science', 'scientific', 'score', 'search', 'second', 'section', 'security', 'seen', 'segment', 'segmentation', 'selected', 'selection', 'self', 'semantic', 'semantics', 'semi', 'sense', 'sensing', 'sensitive', 'sensitivity', 'sensor', 'separation', 'sequence', 'sequential', 'series', 'service', 'set', 'setting', 'setup', 'several', 'shape', 'shared', 'sharing', 'sharp', 'shift', 'short', 'show', 'showed', 'showing', 'shown', 'side', 'sigma', 'signal', 'signature', 'significant', 'significantly', 'sim', 'similar', 'similarity', 'simple', 'simulated', 'simulation', 'simultaneously', 'since', 'single', 'singular', 'site', 'situation', 'size', 'slow', 'small', 'smaller', 'smart', 'smooth', 'social', 'software', 'solar', 'solid', 'soliton', 'solution', 'solve', 'solved', 'solver', 'solving', 'source', 'space', 'sparse', 'sparsity', 'spatial', 'speaker', 'special', 'specie', 'specific', 'specifically', 'spectral', 'spectroscopy', 'spectrum', 'speech', 'speed', 'sphere', 'spin', 'sqrt', 'square', 'stability', 'stable', 'stage', 'standard', 'star', 'state', 'static', 'stationary', 'statistic', 'statistical', 'steady', 'stellar', 'step', 'still', 'stochastic', 'storage', 'strategy', 'stream', 'strength', 'stress', 'string', 'strong', 'strongly', 'structural', 'structure', 'structured', 'studied', 'study', 'studying', 'sub', 'subgroup', 'subject', 'subset', 'subspace', 'success', 'successfully', 'sufficient', 'sufficiently', 'suggest', 'suggests', 'suitable', 'sum', 'super', 'superconducting', 'supervised', 'support', 'surface', 'survey', 'symmetric', 'symmetry', 'synthesis', 'synthetic', 'system', 'systematic', 'take', 'taken', 'taking', 'target', 'task', 'technique', 'technology', 'telescope', 'temperature', 'temporal', 'tensor', 'term', 'test', 'tested', 'testing', 'text', 'th', 'theorem', 'theoretic', 'theoretical', 'theoretically', 'theory', 'therefore', 'thermal', 'theta', 'thin', 'third', 'three', 'threshold', 'thus', 'time', 'together', 'tool', 'top', 'topic', 'topological', 'topology', 'total', 'towards', 'trace', 'tracking', 'trade', 'traditional', 'traffic', 'train', 'trained', 'training', 'trajectory', 'transfer', 'transform', 'transformation', 'transient', 'transition', 'translation', 'transmission', 'transport', 'treatment', 'tree', 'trend', 'trivial', 'true', 'tuning', 'turn', 'two', 'type', 'typical', 'typically', 'uncertainty', 'underlying', 'understand', 'understanding', 'unified', 'uniform', 'unique', 'unit', 'universal', 'unknown', 'unlike', 'unsupervised', 'update', 'upon', 'upper', 'us', 'use', 'used', 'useful', 'user', 'using', 'usually', 'utility', 'validate', 'validation', 'value', 'valued', 'varepsilon', 'variable', 'variance', 'variant', 'variation', 'variational', 'variety', 'various', 'varying', 'vector', 'vehicle', 'velocity', 'verification', 'version', 'vertex', 'via', 'video', 'view', 'virtual', 'vision', 'visual', 'voltage', 'volume', 'vortex', 'walk', 'wall', 'water', 'wave', 'wavelength', 'way', 'weak', 'weakly', 'web', 'weight', 'weighted', 'well', 'whereas', 'whether', 'whole', 'whose', 'wide', 'widely', 'width', 'wind', 'wireless', 'within', 'without', 'word', 'work', 'world', 'would', 'year', 'yet', 'yield', 'zero']\n(20972, 1500) (20972,)\n"
     ]
    }
   ],
   "source": [
    "# Create bag-of-words model\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(max_features = 1500)\n",
    "X = vectorizer.fit_transform(data).toarray()\n",
    "y = dataset.iloc[:,-1].values\n",
    "\n",
    "print(vectorizer.get_feature_names())\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(16777, 1500) (16777,)\n(4195, 1500) (4195,)\n"
     ]
    }
   ],
   "source": [
    "# Split dataset into training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "set()\n[[4144    1]\n [  45    5]]\nAccuracy:  0.9890345649582837\nPrecision:  0.8333333333333334\nRecall:  0.1\nF1:  0.17857142857142858\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# SVM\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "classifier = SVC()\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "print(set(y_test) - set(y_pred))\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "print('Precision: ', precision_score(y_test, y_pred))\n",
    "print('Recall: ', recall_score(y_test, y_pred))\n",
    "print('F1: ', f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python385jvsc74a57bd0a01bd253adf6e1f00cc92ae069bc8c363cf013eb433c05c4da49aa4c35e235f9",
   "display_name": "Python 3.8.5 64-bit ('anaconda3': virtualenv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}